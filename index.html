<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Gaspard  Beugnot</title>
    <meta name="author" content="Gaspard  Beugnot" />
    <meta name="description" content="Gaspard Beugnot's personal webpage. Based on [*folio](https://github.com/bogoli/-folio) design.
" />
    <meta name="keywords" content="machine learning, optimization, non-convex" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="/assets/img/favicon.ico"/>
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://gaspardbb.github.io/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark" />

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item active">
                <a class="nav-link" href="/">about<span class="sr-only">(current)</span></a>
              </li>
              

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">publications</a>
              </li>

              <!-- Toogle theme mode -->
              <div class="toggle-container">
                <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </a>
              </div>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="container mt-5">
      <!-- about.html -->
      <div class="post">
        <header class="post-header">
          <h1 class="post-title">
           <span class="font-weight-bold">Gaspard</span>  Beugnot
          </h1>
          <p class="desc">2nd year PhD student in Machine Learning and Optimization.</p>
        </header>

        <article>
          <div class="profile float-right">
<figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/me-480.webp"></source>
    <source media="(max-width: 800px)" srcset="/assets/img/me-800.webp"></source>
    <source media="(max-width: 1400px)" srcset="/assets/img/me-1400.webp"></source>
    <!-- Fallback to the original file -->
    <img class="img-fluid z-dept-1 rounded" src="/assets/img/me.jpeg" alt="me.jpeg">

  </picture>

</figure>

          </div>

          <div class="clearfix">
            <p>Welcome to my personal page. Learn more about my research interests and my latest news here!</p>

<p>I’m currently a second-year PhD student at ENS and Inria, under the supervision of <a href="thoth.inrialpes.fr/people/mairal/">Julien Mairal</a> and <a href="https://www.di.ens.fr/~rudi/" target="_blank" rel="noopener noreferrer">Alessandro Rudi</a>. My research focuses on theoretical properties of kernel methods in all sorts of flavour, but I’m also interested in providing fast and reliable implementation of my research projects.</p>

<p>Currently, I’m interested in non-convex optimization, and I’m enthusiastic about <a href="https://www.rust-lang.org/" target="_blank" rel="noopener noreferrer">Rust</a> and <a href="https://julialang.org/" target="_blank" rel="noopener noreferrer">Julia</a>, which I hope to use for my research along with Python!</p>

<p>Before that, I graduated from <a href="https://www.polytechnique.edu" target="_blank" rel="noopener noreferrer">Ecole Polytechnique</a> (X2016) and got a master from École Normale Supérieure in Mathematics, Vision and Machine Learning in 2020 (<a href="https://www.master-mva.com/" target="_blank" rel="noopener noreferrer">Master MVA</a>).</p>

          </div>

          <!-- News -->          
          <div class="news">
            <h2>news</h2>
            <div class="table-responsive">
              <table class="table table-sm table-borderless"> 
                <tr>
                  <th scope="row">May 20, 2022</th>
                  <td>
                    Our paper on the influence of the learning on the generalization was accepted at <a href="http://learningtheory.org/colt2022/" target="_blank" rel="noopener noreferrer">COLT22</a>! See you there!
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Apr 15, 2022</th>
                  <td>
                    The learning rate impacts the generalization when training neural network. Did you know it can occur in <strong>convex</strong> settings too? Check <a href="https://arxiv.org/pdf/2202.13733.pdf" target="_blank" rel="noopener noreferrer">our last preprint</a>!
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Sep 28, 2021</th>
                  <td>
                    My paper on the <a href="https://proceedings.neurips.cc/paper/2021/file/eda80a3d5b344bc40f3bc04f65b7a357-Paper.pdf" target="_blank" rel="noopener noreferrer">proximal point method for concordant loss function</a> was awarded a <strong>Spotlight</strong> award at NeurIPS 2021!
 
                  </td>
                </tr> 
              </table>
            </div> 
          </div>

          <!-- Selected papers -->
          <div class="publications">
            <h2>selected publications</h2>
            <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
          <span class="conf badge">NeurIPS21</span>
        
        
          <span class="award badge">Spotlight</span>
        
        </div>

        <!-- Entry bib key -->
        <div id="beugnot2021beyond" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Beyond Tikhonov: faster learning with self-concordant losses, via iterative regularization</div>
          <!-- Author -->
          <div class="author">
                  <em>Beugnot, Gaspard</em>, <a href="thoth.inrialpes.fr/people/mairal/">Mairal, Julien</a>, and <a href="https://www.di.ens.fr/~rudi/" target="_blank" rel="noopener noreferrer">Rudi, Alessandro</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Advances in Neural Information Processing Systems</em> 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://openreview.net/forum?id=eIdzV1-Jdwv" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="https://proceedings.neurips.cc/paper/2021/file/eda80a3d5b344bc40f3bc04f65b7a357-Paper.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://nips.cc/virtual/2021/poster/26184" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Video</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The theory of spectral filtering is a remarkable tool to understand the statistical properties of learning with kernels. For least squares, it allows to derive various regularization schemes that yield faster convergence rates of the excess risk than with Tikhonov regularization. This is typically achieved by leveraging classical assumptions called source and capacity conditions, which characterize the difficulty of the learning task. In order to understand estimators derived from other loss functions, Marteau-Ferey et al. have extended the theory of Tikhonov regularization to generalized self concordant loss functions (GSC), which contain, e.g., the logistic loss. In this paper, we go a step further and show that fast and optimal rates can be achieved for GSC by using the iterated Tikhonov regularization scheme, which is intrinsically related to the proximal point method in optimization, and overcomes the limitation of the classical Tikhonov regularization.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
          <span class="conf badge">COLT22</span>
        
        
        </div>

        <!-- Entry bib key -->
        <div id="beugnot22stepsizeconvex" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">On the Benefits of Large Learning Rates for Kernel Methods</div>
          <!-- Author -->
          <div class="author">
                  <em>Beugnot, Gaspard</em>, <a href="thoth.inrialpes.fr/people/mairal/">Mairal, Julien</a>, and <a href="https://www.di.ens.fr/~rudi/" target="_blank" rel="noopener noreferrer">Rudi, Alessandro</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="http://arxiv.org/abs/https://arxiv.org/abs/2202.13733" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a>
            <a href="https://arxiv.org/pdf/2202.13733.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This paper studies an intriguing phenomenon related to the good generalization performance of estimators obtained by using large  learning rates within gradient descent algorithms. First observed in the deep learning literature, we show that a phenomenon can be precisely characterized in the context of kernel methods, even though the resulting optimization problem is convex. Specifically, we consider the minimization of a quadratic objective in a separable Hilbert space, and show that with early stopping, the choice of learning rate influences the spectral decomposition of the obtained solution on the Hessian’s eigenvectors. This extends an intuition described by Nakkiran (2020) on a two-dimensional toy problem to realistic learning scenarios such as kernel ridge regression. While large learning rates may be proven beneficial as soon as there is a mismatch between the train and test objectives, we further explain why it already occurs in classification tasks without assuming any particular mismatch between train and test data distributions.</p>
          </div>
        </div>
      </div>
</li>
</ol>
          </div>

          <!-- Social -->
          <div class="social">
            <div class="contact-icons">
            <a href="mailto:%67%61%73%70%61%72%64.%62%65%75%67%6E%6F%74@%69%6E%72%69%61.%66%72" title="email"><i class="fas fa-envelope"></i></a>
            <a href="https://scholar.google.com/citations?user=BlUp23oAAAAJ" title="Google Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i></a>
            <a href="https://github.com/gaspardbb" title="GitHub" target="_blank" rel="noopener noreferrer"><i class="fab fa-github"></i></a>
            <a href="https://www.linkedin.com/in/gaspard-beugnot" title="LinkedIn" target="_blank" rel="noopener noreferrer"><i class="fab fa-linkedin"></i></a>
            <a href="https://twitter.com/gaspardbt" title="Twitter" target="_blank" rel="noopener noreferrer"><i class="fab fa-twitter"></i></a>
            
            </div>

            <div class="contact-note">
              Best way to reach me is by mail!

            </div>
            
          </div>
        </article>

</div>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2022 Gaspard  Beugnot. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme.
Last updated: June 20, 2022.
      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script src="/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
  </body>
</html>

